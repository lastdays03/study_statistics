{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Session 2: í™•ë¥ ê³¼ ë¶„í¬ (Integrated)\n",
                "\n",
                "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
                "- **Deep Theory**: í™•ë¥ ì˜ 3ê°€ì§€ ê³µë¦¬ì™€ ì¡°ê±´ë¶€ í™•ë¥ , ë² ì´ì¦ˆ ì •ë¦¬ì˜ ìˆ˜ì‹ì  ì˜ë¯¸ë¥¼ ì´í•´í•©ë‹ˆë‹¤.\n",
                "- **Practice**: ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ê³¼ Bigram í™•ë¥ ì„ ì§ì ‘ êµ¬í˜„í•´ë´…ë‹ˆë‹¤.\n",
                "- **Concepts**: í™•ë¥  ë³€ìˆ˜ì™€ ì£¼ìš” ë¶„í¬(ì •ê·œ, ë¡œê·¸ ì •ê·œ, Zipf)ì˜ íŠ¹ì„±ì„ íŒŒì•…í•©ë‹ˆë‹¤.\n",
                "- **Experiment**: ëª¬í‹° í™€ ë¬¸ì œë¥¼ í†µí•´ ì¡°ê±´ë¶€ í™•ë¥ ì˜ ì§ê´€ì„ ê²€ì¦í•©ë‹ˆë‹¤.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 1. ğŸ“ Deep Theory: í™•ë¥ ì˜ ë³¸ì§ˆ\n",
                "\n",
                "## 1. í™•ë¥ ì˜ ê¸°ì´ˆ (Axioms of Probability)\n",
                "\n",
                "í‘œë³¸ ê³µê°„(Sample Space) $\\Omega$ì—ì„œ ì‚¬ê±´(Event) $E$ê°€ ì¼ì–´ë‚  í™•ë¥  $P(E)$ëŠ” ë‹¤ìŒ 3ê°€ì§€ ê³µë¦¬ë¥¼ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤ (Kolmogorov axioms).\n",
                "\n",
                "1.  **Non-negativity**: ëª¨ë“  ì‚¬ê±´ $E$ì— ëŒ€í•´ $P(E) \\ge 0$.\n",
                "2.  **Normalization**: ì „ì²´ í‘œë³¸ ê³µê°„ì˜ í™•ë¥ ì€ 1ì´ë‹¤. $P(\\Omega) = 1$.\n",
                "3.  **Additivity**: ì„œë¡œ ë°°ë°˜ì¸ ì‚¬ê±´ë“¤($E_1, E_2, ...$ where $E_i \\cap E_j = \\emptyset$)ì˜ í•©ì§‘í•© í™•ë¥ ì€ ê° í™•ë¥ ì˜ í•©ê³¼ ê°™ë‹¤.\n",
                "    $$ P(\\bigcup_{i=1}^{\\infty} E_i) = \\sum_{i=1}^{\\infty} P(E_i) $$\n",
                "\n",
                "## 2. ì¡°ê±´ë¶€ í™•ë¥  (Conditional Probability)\n",
                "\n",
                "ì‚¬ê±´ $B$ê°€ ì¼ì–´ë‚¬ë‹¤ëŠ” ì „ì œ í•˜ì— ì‚¬ê±´ $A$ê°€ ì¼ì–´ë‚  í™•ë¥ ì…ë‹ˆë‹¤.\n",
                "\n",
                "$$ P(A|B) = \\frac{P(A \\cap B)}{P(B)} $$\n",
                "\n",
                "> **Insight**: $P(B)$ë¡œ ë‚˜ëˆ„ì–´ì¤€ë‹¤ëŠ” ê²ƒì€, ì „ì²´ í‘œë³¸ ê³µê°„ì„ $\\Omega$ì—ì„œ $B$ë¡œ **'ì¶•ì†Œ(Normalize)'** ì‹œí‚¨ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.\n",
                "\n",
                "## 3. ë² ì´ì¦ˆ ì •ë¦¬ (Bayes' Theorem)\n",
                "\n",
                "ì¡°ê±´ë¶€ í™•ë¥ ì˜ ì •ì˜ë¥¼ ë’¤ì§‘ì–´ì„œ, $P(A|B)$ì™€ $P(B|A)$ì˜ ê´€ê³„ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.\n",
                "\n",
                "$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\n",
                "\n",
                "- $P(A)$: ì‚¬ì „ í™•ë¥  (Prior) - ì¦ê±°ë¥¼ ë³´ê¸° ì „ì˜ ë¯¿ìŒ\n",
                "- $P(B|A)$: ìš°ë„ (Likelihood) - ê°€ì„¤ $A$ê°€ ë§ì„ ë•Œ ì¦ê±° $B$ê°€ ê´€ì¸¡ë  í™•ë¥ \n",
                "- $P(A|B)$: ì‚¬í›„ í™•ë¥  (Posterior) - ì¦ê±° $B$ë¥¼ ë³¸ í›„ ê°±ì‹ ëœ ë¯¿ìŒ\n",
                "\n",
                "## 4. PDFì™€ CDF\n",
                "\n",
                "- **PDF (Probability Density Function, $f(x)$)**: ì—°ì† í™•ë¥  ë³€ìˆ˜ì˜ íŠ¹ì • êµ¬ê°„ì—ì„œì˜ ë°€ë„.\n",
                "- **CDF (Cumulative Distribution Function, $F(x)$)**: $-\\infty$ë¶€í„° $x$ê¹Œì§€ì˜ í™•ë¥  ëˆ„ì .\n",
                "- ê´€ê³„: $F(x) = \\int_{-\\infty}^{x} f(t) dt$, ë°˜ëŒ€ë¡œ $f(x) = \\frac{d}{dx}F(x)$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 2. ğŸ’» Manual Implementation: ì‹œë®¬ë ˆì´ì…˜ê³¼ í™•ë¥ \n",
                "\n",
                "### ë¯¸ì…˜ 1: ëª¬í…Œì¹´ë¥¼ë¡œ(Monte Carlo) ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ $\\pi$ êµ¬í•˜ê¸°\n",
                "ì‚¬ê°í˜• ì•ˆì— ì›ì„ ê·¸ë¦¬ê³ , ë¬´ì‘ìœ„ë¡œ ì ì„ ì°ì—ˆì„ ë•Œ ì› ì•ˆì— ë“¤ì–´ê°ˆ í™•ë¥ ì€ ë©´ì ë¹„($\\pi/4$)ì™€ ê°™ìŠµë‹ˆë‹¤.\n",
                "ì´ë¥¼ ì´ìš©í•´ $\\pi$ë¥¼ ì¶”ì •í•´ë³´ì„¸ìš”."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import random\n",
                "\n",
                "def estimate_pi(n_samples):\n",
                "    inside_circle = 0\n",
                "    \n",
                "    for _ in range(n_samples):\n",
                "        x = random.random() # 0 ~ 1 ì‚¬ì´\n",
                "        y = random.random()\n",
                "        \n",
                "        # ì›ì (0,0)ì—ì„œì˜ ê±°ë¦¬ê°€ 1 ì´í•˜ì´ë©´ ì› ì•ˆ\n",
                "        if x**2 + y**2 <= 1:\n",
                "            inside_circle += 1\n",
                "            \n",
                "    return (inside_circle / n_samples) * 4\n",
                "\n",
                "# ì‹¤í—˜\n",
                "for n in [100, 1000, 10000, 100000]:\n",
                "    print(f\"N={n}, Pi={estimate_pi(n):.5f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ë¯¸ì…˜ 2: Bigram í™•ë¥  ê³„ì‚°ê¸°\n",
                "ê°„ë‹¨í•œ ì½”í¼ìŠ¤ë¥¼ ì£¼ê³ , $P(\\text{word}|\\text{prev_word})$ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“­ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "corpus = \"I am a boy and I am a student\".split()\n",
                "\n",
                "def calc_bigram_prob(prev, word, corpus):\n",
                "    # TODO: ì¡°ê±´ë¶€ í™•ë¥  P(word|prev) ê³„ì‚°\n",
                "    # P(word|prev) = Count(prev, word) / Count(prev)\n",
                "    \n",
                "    bigram_count = 0\n",
                "    prev_count = 0\n",
                "    \n",
                "    for i in range(len(corpus) - 1):\n",
                "        if corpus[i] == prev:\n",
                "            prev_count += 1\n",
                "            if corpus[i+1] == word:\n",
                "                bigram_count += 1\n",
                "                \n",
                "    if prev_count == 0:\n",
                "        return 0\n",
                "    return bigram_count / prev_count\n",
                "\n",
                "print(f\"P(a|am) = {calc_bigram_prob('am', 'a', corpus)}\")\n",
                "print(f\"P(student|a) = {calc_bigram_prob('a', 'student', corpus)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# ğŸš€ Practical Usage: Scipy & Random\n",
                "\n",
                "ë³µì¡í•œ í™•ë¥ ë°€ë„í•¨ìˆ˜(PDF)ë¥¼ ì§ì ‘ ì ë¶„í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. `scipy.stats`ê°€ ë‹¤ í•´ì¤ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy import stats\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# 1. ì •ê·œë¶„í¬(Normal Dist)\n",
                "# í‰ê· =0, í‘œì¤€í¸ì°¨=1ì¸ í‘œì¤€ì •ê·œë¶„í¬ ê°ì²´\n",
                "norm_dist = stats.norm(loc=0, scale=1)\n",
                "\n",
                "# -1.96 ~ +1.96 ì‚¬ì´ì˜ í™•ë¥  (ì¦‰ 95% êµ¬ê°„)\n",
                "prob_95 = norm_dist.cdf(1.96) - norm_dist.cdf(-1.96)\n",
                "print(f\"Prob in [-1.96, 1.96]: {prob_95:.4f}\")\n",
                "\n",
                "# 2. íŠ¹ì • ê°’ì—ì„œì˜ í™•ë¥ ë°€ë„ (PDF)\n",
                "x = np.linspace(-3, 3, 100)\n",
                "y = norm_dist.pdf(x)\n",
                "\n",
                "plt.figure(figsize=(8, 4))\n",
                "plt.plot(x, y, label='Normal PDF')\n",
                "plt.fill_between(x, y, alpha=0.3)\n",
                "plt.title(\"Standard Normal Distribution\")\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 3. ğŸ“– Concepts & Practice: ë¶„í¬ì˜ ì„¸ê³„\n",
                "\n",
                "## Zipf's Law (ë©± ë²•ì¹™)\n",
                "ìì—°ì–´ì—ì„œ ë‹¨ì–´ì˜ ë¹ˆë„ëŠ” ìˆœìœ„(Rank)ì— ë°˜ë¹„ë¡€í•©ë‹ˆë‹¤.\n",
                "$$ P(x) \\propto x^{-\\alpha} $$\n",
                "ëŒ€ë¶€ë¶„ì˜ ë‹¨ì–´ëŠ” ì•„ì£¼ ì¡°ê¸ˆ ë‚˜ì˜¤ê³ , ì†Œìˆ˜ì˜ ë‹¨ì–´ê°€ ì—„ì²­ë‚˜ê²Œ ë§ì´ ë‚˜ì˜µë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Zipf ë¶„í¬ ìƒì„± (a=1.5)\n",
                "zipf_data = np.random.zipf(a=1.5, size=1000)\n",
                "\n",
                "# ìƒìœ„ 50ê°œë§Œ ì‹œê°í™”\n",
                "from collections import Counter\n",
                "counts = Counter(zipf_data)\n",
                "sorted_counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)[:50]\n",
                "\n",
                "ranks = range(1, len(sorted_counts)+1)\n",
                "freqs = [x[1] for x in sorted_counts]\n",
                "\n",
                "plt.figure(figsize=(12, 5))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.bar(ranks, freqs)\n",
                "plt.title(\"Word Frequency (Linear Scale)\")\n",
                "plt.xlabel(\"Rank\")\n",
                "plt.ylabel(\"Frequency\")\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.loglog(ranks, freqs, marker='o')\n",
                "plt.title(\"Word Frequency (Log-Log Scale)\")\n",
                "plt.xlabel(\"Log Rank\")\n",
                "plt.ylabel(\"Log Frequency\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 4. ğŸ§ª Experiment: ëª¬í‹° í™€ ë¬¸ì œ (Monty Hall Problem)\n",
                "\n",
                "**ìƒí™©**: ë¬¸ 3ê°œ ì¤‘ í•˜ë‚˜ì— ì°¨ê°€ ìˆê³ , ë‚˜ë¨¸ì§€ ë‘˜ì—” ì—¼ì†Œê°€ ìˆìŠµë‹ˆë‹¤. í•˜ë‚˜ë¥¼ ê³ ë¥´ë©´, ì‚¬íšŒìê°€ ë‚¨ì€ ë¬¸ ì¤‘ ì—¼ì†Œê°€ ìˆëŠ” ë¬¸ì„ ì—´ì–´ì¤ë‹ˆë‹¤. ë°”ê¾¸ëŠ” ê²Œ ìœ ë¦¬í• ê¹Œìš”?\n",
                "\n",
                "- **Stay**: ì²˜ìŒì— ê³ ë¥¸ ë¬¸ì„ ìœ ì§€.\n",
                "- **Switch**: ë‹¤ë¥¸ ë¬¸ìœ¼ë¡œ ë°”ê¿ˆ.\n",
                "\n",
                "ì§ê´€ì ìœ¼ë¡œëŠ” ë°˜ë°˜(50%) ê°™ì§€ë§Œ, ì¡°ê±´ë¶€ í™•ë¥ ë¡œ ê³„ì‚°í•˜ë©´ **ë°”ê¾¸ëŠ” ê²Œ 2ë°° ìœ ë¦¬(66%)**í•©ë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ê²€ì¦í•´ë´…ì‹œë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def monty_hall(strategy='stay', n_trials=1000):\n",
                "    wins = 0\n",
                "    \n",
                "    for _ in range(n_trials):\n",
                "        doors = [0, 0, 1] # 1 is Car\n",
                "        random.shuffle(doors)\n",
                "        \n",
                "        choice = random.randint(0, 2)\n",
                "        \n",
                "        # ì‚¬íšŒìê°€ ì—¼ì†Œ ë¬¸ì„ ì—°ë‹¤ (ë‚´ê°€ ê³ ë¥¸ ê²ƒ ì œì™¸, ì°¨ê°€ ìˆëŠ” ê²ƒ ì œì™¸)\n",
                "        # ë‚¨ì€ ë¬¸ ì¤‘ ì°¨ê°€ ìˆëŠ” ë¬¸ì„ ì„ íƒí•˜ë©´ ìŠ¹ë¦¬\n",
                "        \n",
                "        if strategy == 'stay':\n",
                "            if doors[choice] == 1:\n",
                "                wins += 1\n",
                "        elif strategy == 'switch':\n",
                "            # ë‚´ê°€ ê³ ë¥´ì§€ ì•Šì€ ë‚˜ë¨¸ì§€ ë‘ ë¬¸ ì¤‘ í•˜ë‚˜ëŠ” ì—¼ì†Œì„. \n",
                "            # ì‚¬íšŒìê°€ ê·¸ ì—¼ì†Œ ë¬¸ì„ ì—´ì–´ì¤Œ.\n",
                "            # ë‚´ê°€ ë°”ê¾¼ ë¬¸ì— ì°¨ê°€ ìˆìœ¼ë ¤ë©´? -> ì• ì´ˆì— ë‚´ê°€ ì—¼ì†Œë¥¼ ê³¨ëìœ¼ë©´ ë¨.\n",
                "            if doors[choice] == 0:\n",
                "                wins += 1\n",
                "                \n",
                "    return wins / n_trials\n",
                "\n",
                "print(f\"Win Rate (Stay): {monty_hall('stay') * 100:.2f}%\")\n",
                "print(f\"Win Rate (Switch): {monty_hall('switch') * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> **Discussion**: ì½”ë“œë¡œ ëŒë ¤ë³´ë‹ˆ ì •ë§ë¡œ Switchê°€ ì•½ 66% ìŠ¹ë¥ ì´ ë‚˜ì˜µë‹ˆë‹¤. ì¡°ê±´ë¶€ í™•ë¥ (ìƒˆë¡œìš´ ì •ë³´ê°€ ì¶”ê°€ë˜ì—ˆì„ ë•Œì˜ í™•ë¥ )ì˜ í˜ì…ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 5. ğŸ›  Library Mapping: ì‹¤ì „ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—°ê²°\n",
                "\n",
                "í™•ë¥ ê³¼ í†µê³„ë¥¼ ì†ìœ¼ë¡œ êµ¬í˜„í•˜ëŠ” ê²ƒë„ ì¢‹ì§€ë§Œ, ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
                "\n",
                "### 1. N-gram Count (Bigram)\n",
                "- **Manual**: ì´ì¤‘ Loopë¡œ ì§ì ‘ ì¹´ìš´íŒ…\n",
                "- **Library**: `sklearn.feature_extraction.text.CountVectorizer(ngram_range=(2, 2))`\n",
                "\n",
                "### 2. ìˆœì—´ê³¼ ì¡°í•© (Permutations & Combinations)\n",
                "- `math.comb(n, k)`: ì¡°í•© ($nCk$)\n",
                "- `math.perm(n, k)`: ìˆœì—´ ($nPk$)\n",
                "- `scipy.special.comb`: ì‹¤ìˆ˜ ë²”ìœ„ê¹Œì§€ í™•ì¥ëœ ì¡°í•© ê³„ì‚° (ê°ë§ˆ í•¨ìˆ˜ ê¸°ë°˜)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "import math\n",
                "\n",
                "corpus = [\"I am a boy\", \"I am a student\"]\n",
                "\n",
                "# Bigram Count\n",
                "vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
                "X = vectorizer.fit_transform(corpus)\n",
                "print(\"Bigram Features:\", vectorizer.get_feature_names_out())\n",
                "print(\"Counts:\\n\", X.toarray())\n",
                "\n",
                "# Combinations\n",
                "n, k = 5, 2\n",
                "print(f\"\\n{n}C{k} (Combination): {math.comb(n, k)}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}