{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Session 3: ìƒê´€ê´€ê³„ì™€ ì˜ˆì¸¡ ëª¨ë¸ (Integrated)\n",
                "\n",
                "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
                "- **Deep Theory**: ê³µë¶„ì‚°ê³¼ ìƒê´€ê³„ìˆ˜, ê·¸ë¦¬ê³  ìµœì†Œì œê³±ë²•(OLS)ì˜ ë¯¸ë¶„ ê³¼ì •ì„ ì´í•´í•©ë‹ˆë‹¤.\n",
                "- **Practice**: ê²½ì‚¬í•˜ê°•ë²•(Gradient Descent)ì„ ì§ì ‘ êµ¬í˜„í•˜ì—¬ ì„ í˜• íšŒê·€ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
                "- **Concepts**: ìƒê´€ê´€ê³„ì™€ ì¸ê³¼ê´€ê³„ë¥¼ êµ¬ë¶„í•˜ê³ , ì„ í˜• ëª¨ë¸ì˜ í•œê³„ë¥¼ ë°°ì›ë‹ˆë‹¤.\n",
                "- **Experiment**: ë…¸ì´ì¦ˆê°€ ëª¨ë¸ í•™ìŠµì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‹¤í—˜í•©ë‹ˆë‹¤.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 1. ğŸ“ Deep Theory: ê´€ê³„ì™€ í•™ìŠµ\n",
                "\n",
                "## 1. ê³µë¶„ì‚°(Covariance)ê³¼ ìƒê´€ê³„ìˆ˜(Correlation)\n",
                "\n",
                "ë‘ ë³€ìˆ˜ $X, Y$ê°€ í•¨ê»˜ ë³€í•˜ëŠ” ì •ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.\n",
                "\n",
                "$$ Cov(X, Y) = \\frac{1}{n-1} \\sum (x_i - \\bar{x})(y_i - \\bar{y}) $$\n",
                "\n",
                "- **ê³µë¶„ì‚°ì˜ ë¬¸ì œ**: $X, Y$ì˜ ë‹¨ìœ„(Scale)ì— ë”°ë¼ ê°’ì´ ë„ˆë¬´ ì»¤ì§€ê±°ë‚˜ ì‘ì•„ì§‘ë‹ˆë‹¤.\n",
                "- **í•´ê²° (ì •ê·œí™”)**: ê° ë³€ìˆ˜ì˜ í‘œì¤€í¸ì°¨ë¡œ ë‚˜ëˆ„ì–´ $-1 \\sim 1$ ì‚¬ì´ ê°’ìœ¼ë¡œ ë§ì¶¥ë‹ˆë‹¤. -> **ìƒê´€ê³„ìˆ˜($r$)**\n",
                "\n",
                "$$ r_{xy} = \\frac{Cov(X, Y)}{s_x s_y} $$\n",
                "\n",
                "## 2. ìµœì†Œì œê³±ë²• (Ordinary Least Squares)\n",
                "\n",
                "ë°ì´í„° $y$ì™€ ì˜ˆì¸¡ $\\hat{y} = wx + b$ ì‚¬ì´ì˜ ì˜¤ì°¨ ì œê³±í•©(SSE)ì„ ìµœì†Œí™”í•˜ëŠ” $w, b$ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
                "\n",
                "$$ Loss = \\sum (y_i - (wx_i + b))^2 $$\n",
                "\n",
                "ì´ Loss í•¨ìˆ˜ëŠ” ì•„ë˜ë¡œ ë³¼ë¡í•œ(Convex) 2ì°¨ í•¨ìˆ˜ì´ë¯€ë¡œ, **ë¯¸ë¶„í•´ì„œ 0ì´ ë˜ëŠ” ì§€ì **ì´ ìµœì†Ÿê°’ì…ë‹ˆë‹¤.\n",
                "\n",
                "$$ \\frac{\\partial Loss}{\\partial w} = -2 \\sum x_i(y_i - (wx_i + b)) = 0 $$\n",
                "$$ \\frac{\\partial Loss}{\\partial b} = -2 \\sum (y_i - (wx_i + b)) = 0 $$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 2. ğŸ’» Manual Implementation: ê²½ì‚¬í•˜ê°•ë²• (Gradient Descent)\n",
                "\n",
                "ë¯¸ë¶„ ê³µì‹ì„ ì´ìš©í•˜ì—¬, ì¡°ê¸ˆì”© ê²½ì‚¬ë¥¼ íƒ€ê³  ë‚´ë ¤ê°€ ìµœì ì˜ $w, b$ë¥¼ ì°¾ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
                "$$ w_{new} = w_{old} - \\alpha \\frac{\\partial Loss}{\\partial w} $$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# ê°€ìƒì˜ ë°ì´í„° ìƒì„± (y = 2x + 1 + noise)\n",
                "np.random.seed(42)\n",
                "X = np.random.rand(100, 1)\n",
                "y = 2 * X + 1 + np.random.randn(100, 1) * 0.1\n",
                "\n",
                "def gradient_descent(X, y, lr=0.1, epochs=1000):\n",
                "    w = np.random.randn(1, 1)\n",
                "    b = np.random.randn(1, 1)\n",
                "    N = len(y)\n",
                "    \n",
                "    for _ in range(epochs):\n",
                "        # ì˜ˆì¸¡\n",
                "        y_pred = X * w + b\n",
                "        \n",
                "        # í¸ë¯¸ë¶„ (Gradient ê³„ì‚°)\n",
                "        # dLoss/dw = -2/N * sum(x * error)\n",
                "        error = y - y_pred\n",
                "        dw = -2 * np.sum(X * error) / N  # í‰ê· ì œê³±ì˜¤ì°¨ ê¸°ì¤€\n",
                "        db = -2 * np.sum(error) / N\n",
                "        \n",
                "        # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
                "        w = w - lr * dw\n",
                "        b = b - lr * db\n",
                "        \n",
                "    return w, b\n",
                "\n",
                "w_hat, b_hat = gradient_descent(X, y)\n",
                "print(f\"Estimated: w={w_hat[0][0]:.4f}, b={b_hat[0][0]:.4f} (Actual: w=2, b=1)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 3. ğŸ“– Concepts & Practice: ìƒê´€ ë¶„ì„\n",
                "\n",
                "### íˆíŠ¸ë§µ(Heatmap)ìœ¼ë¡œ ìƒê´€ê´€ê³„ ì‹œê°í™”\n",
                "ë³€ìˆ˜ê°€ ë§ì„ ë•ŒëŠ” íˆíŠ¸ë§µì´ ìœ ìš©í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "import pandas as pd\n",
                "\n",
                "# ì˜ˆì œ ë°ì´í„°í”„ë ˆì„\n",
                "df = pd.DataFrame({'X': X.flatten(), 'Y': y.flatten()})\n",
                "df['Z'] = np.random.rand(100) # ì•„ë¬´ ê´€ë ¨ ì—†ëŠ” ë³€ìˆ˜\n",
                "\n",
                "corr = df.corr()\n",
                "\n",
                "plt.figure(figsize=(6, 5))\n",
                "sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
                "plt.title(\"Correlation Heatmap\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 4. ğŸ§ª Experiment: ë…¸ì´ì¦ˆì™€ ëª¨ë¸\n",
                "\n",
                "### Scenario: ë…¸ì´ì¦ˆê°€ ë§ì•„ì§€ë©´ í•™ìŠµì´ ì–´ë–»ê²Œ ë ê¹Œ?\n",
                "ë°ì´í„°ì— ì¡ìŒ(Noise)ì´ ì»¤ì§ˆìˆ˜ë¡ íšŒê·€ì„ ì´ ì •ë‹µ(Truth)ì—ì„œ ë©€ì–´ì§€ê³  ì‹ ë¢°ë„ê°€ ë–¨ì–´ì§€ëŠ” ê²ƒì„ í™•ì¸í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "noise_levels = [0.1, 0.5, 1.0, 2.0]\n",
                "\n",
                "plt.figure(figsize=(15, 3))\n",
                "\n",
                "for i, noise in enumerate(noise_levels):\n",
                "    # ë…¸ì´ì¦ˆ ì¶”ê°€\n",
                "    y_noisy = 2 * X + 1 + np.random.randn(100, 1) * noise\n",
                "    \n",
                "    # í•™ìŠµ\n",
                "    w_n, b_n = gradient_descent(X, y_noisy)\n",
                "    \n",
                "    # ì‹œê°í™”\n",
                "    plt.subplot(1, 4, i+1)\n",
                "    plt.scatter(X, y_noisy, alpha=0.5, s=10)\n",
                "    plt.plot(X, X*w_n + b_n, color='red')\n",
                "    plt.title(f\"Noise={noise}\\nw={w_n[0][0]:.2f}\")\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> **Discussion**: ë…¸ì´ì¦ˆê°€ ì»¤ì§ˆìˆ˜ë¡ ë°ì´í„°ê°€ í¼ì§€ê³ , $w$ê°’ì˜ ë³€ë™ì„±ë„ ì»¤ì§‘ë‹ˆë‹¤. (ëª¨ë¸ì˜ Variance ì¦ê°€)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}