{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Session 3: ìƒê´€ê´€ê³„ì™€ ì˜ˆì¸¡ ëª¨ë¸ (Integrated)\n",
                "\n",
                "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
                "- **Deep Theory**: ê³µë¶„ì‚°ê³¼ ìƒê´€ê³„ìˆ˜, ê·¸ë¦¬ê³  ìµœì†Œì œê³±ë²•(OLS)ì˜ ë¯¸ë¶„ ê³¼ì •ì„ ì´í•´í•©ë‹ˆë‹¤.\n",
                "- **Practice**: ê²½ì‚¬í•˜ê°•ë²•(Gradient Descent)ì„ ì§ì ‘ êµ¬í˜„í•˜ì—¬ ì„ í˜• íšŒê·€ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
                "- **Visualization**: ì‚°ì ë„ì™€ íšŒê·€ì„ ì„ í†µí•´ ë°ì´í„°ì˜ íŒ¨í„´ê³¼ ì´ìƒì¹˜ë¥¼ ëˆˆìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤. (Anscombe's Quartet)\n",
                "- **Concepts**: ìƒê´€ê´€ê³„ì™€ ì¸ê³¼ê´€ê³„ë¥¼ êµ¬ë¶„í•˜ê³ , ì„ í˜• ëª¨ë¸ì˜ í•œê³„ë¥¼ ë°°ì›ë‹ˆë‹¤.\n",
                "- **Experiment**: ë…¸ì´ì¦ˆì™€ ì´ìƒì¹˜ê°€ ëª¨ë¸ í•™ìŠµì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‹¤í—˜í•©ë‹ˆë‹¤.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 1. ğŸ“ Deep Theory: ê´€ê³„ì™€ í•™ìŠµ\n",
                "\n",
                "## 1. ê³µë¶„ì‚°(Covariance)ê³¼ ìƒê´€ê³„ìˆ˜(Correlation)\n",
                "\n",
                "ë‘ ë³€ìˆ˜ $X, Y$ê°€ í•¨ê»˜ ë³€í•˜ëŠ” ì •ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.\n",
                "\n",
                "$$ Cov(X, Y) = \\frac{1}{n-1} \\sum (x_i - \\bar{x})(y_i - \\bar{y}) $$\n",
                "\n",
                "- **ê³µë¶„ì‚°ì˜ ë¬¸ì œ**: $X, Y$ì˜ ë‹¨ìœ„(Scale)ì— ë”°ë¼ ê°’ì´ ë„ˆë¬´ ì»¤ì§€ê±°ë‚˜ ì‘ì•„ì§‘ë‹ˆë‹¤.\n",
                "- **í•´ê²° (ì •ê·œí™”)**: ê° ë³€ìˆ˜ì˜ í‘œì¤€í¸ì°¨ë¡œ ë‚˜ëˆ„ì–´ $-1 \\sim 1$ ì‚¬ì´ ê°’ìœ¼ë¡œ ë§ì¶¥ë‹ˆë‹¤. -> **ìƒê´€ê³„ìˆ˜($r$)**\n",
                "\n",
                "$$ r_{xy} = \\frac{Cov(X, Y)}{s_x s_y} $$\n",
                "\n",
                "## 2. ìµœì†Œì œê³±ë²• (Ordinary Least Squares)\n",
                "\n",
                "ë°ì´í„° $y$ì™€ ì˜ˆì¸¡ $\\hat{y} = wx + b$ ì‚¬ì´ì˜ ì˜¤ì°¨ ì œê³±í•©(SSE)ì„ ìµœì†Œí™”í•˜ëŠ” $w, b$ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
                "\n",
                "$$ Loss = \\sum (y_i - (wx_i + b))^2 $$\n",
                "\n",
                "ì´ Loss í•¨ìˆ˜ëŠ” ì•„ë˜ë¡œ ë³¼ë¡í•œ(Convex) 2ì°¨ í•¨ìˆ˜ì´ë¯€ë¡œ, **ë¯¸ë¶„í•´ì„œ 0ì´ ë˜ëŠ” ì§€ì **ì´ ìµœì†Ÿê°’ì…ë‹ˆë‹¤.\n",
                "\n",
                "$$ \\frac{\\partial Loss}{\\partial w} = -2 \\sum x_i(y_i - (wx_i + b)) = 0 $$\n",
                "$$ \\frac{\\partial Loss}{\\partial b} = -2 \\sum (y_i - (wx_i + b)) = 0 $$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 2. ğŸ’» Manual Implementation: ê²½ì‚¬í•˜ê°•ë²• (Gradient Descent)\n",
                "\n",
                "ë¯¸ë¶„ ê³µì‹ì„ ì´ìš©í•˜ì—¬, ì¡°ê¸ˆì”© ê²½ì‚¬ë¥¼ íƒ€ê³  ë‚´ë ¤ê°€ ìµœì ì˜ $w, b$ë¥¼ ì°¾ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
                "$$ w_{new} = w_{old} - \\alpha \\frac{\\partial Loss}{\\partial w} $$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# ê°€ìƒì˜ ë°ì´í„° ìƒì„± (y = 2x + 1 + noise)\n",
                "np.random.seed(42)\n",
                "X = np.random.rand(100, 1)\n",
                "y = 2 * X + 1 + np.random.randn(100, 1) * 0.1\n",
                "\n",
                "def gradient_descent(X, y, lr=0.1, epochs=1000):\n",
                "    w = np.random.randn(1, 1)\n",
                "    b = np.random.randn(1, 1)\n",
                "    N = len(y)\n",
                "    \n",
                "    for _ in range(epochs):\n",
                "        # ì˜ˆì¸¡\n",
                "        y_pred = X * w + b\n",
                "        \n",
                "        # í¸ë¯¸ë¶„ (Gradient ê³„ì‚°)\n",
                "        # dLoss/dw = -2/N * sum(x * error)\n",
                "        error = y - y_pred\n",
                "        dw = -2 * np.sum(X * error) / N  # í‰ê· ì œê³±ì˜¤ì°¨ ê¸°ì¤€\n",
                "        db = -2 * np.sum(error) / N\n",
                "        \n",
                "        # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
                "        w = w - lr * dw\n",
                "        b = b - lr * db\n",
                "        \n",
                "    return w, b\n",
                "\n",
                "w_hat, b_hat = gradient_descent(X, y)\n",
                "print(f\"Estimated: w={w_hat[0][0]:.4f}, b={b_hat[0][0]:.4f} (Actual: w=2, b=1)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# ğŸš€ Practical Usage: Scikit-learn & Pandas\n",
                "\n",
                "ì†ìœ¼ë¡œ ì§œëŠ” ê²½ì‚¬í•˜ê°•ë²•ì€ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤. `sklearn`ì€ ìµœì í™”ëœ C++ ë°±ì—”ë“œë¡œ ìˆœì‹ê°„ì— ë‹µì„ êµ¬í•´ì¤ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LinearRegression\n",
                "import pandas as pd\n",
                "\n",
                "# 1. Linear Regression (OLS)\n",
                "model = LinearRegression()\n",
                "model.fit(X, y)\n",
                "\n",
                "print(f\"Sklearn Coef (w): {model.coef_[0][0]:.4f}\")\n",
                "print(f\"Sklearn Intercept (b): {model.intercept_[0]:.4f}\")\n",
                "\n",
                "# 2. Correlation Matrix\n",
                "df = pd.DataFrame({'X': X.flatten(), 'Y': y.flatten()})\n",
                "print(\"\\nCorrelation Table:\")\n",
                "print(df.corr())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 3. ğŸ“– Concepts & Visualization: ë°ì´í„°ì˜ ì§„ì‹¤ì„ ë³´ëŠ” ëˆˆ\n",
                "\n",
                "## 1. ì™œ ì‹œê°í™”ê°€ ì¤‘ìš”í•œê°€? (Anscombe's Quartet)\n",
                "\n",
                "ìœ ëª…í•œ ì˜ˆì‹œì¸ 'ì•¤ìŠ¤ì»´ì˜ ì½°ë¥´í…Ÿ'ì€ 4ê°œì˜ ë°ì´í„°ì…‹ì´ **í‰ê· , ë¶„ì‚°, ìƒê´€ê³„ìˆ˜, íšŒê·€ì„ ê¹Œì§€ ëª¨ë‘ ë™ì¼**í•©ë‹ˆë‹¤.\n",
                "í•˜ì§€ë§Œ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ë³´ë©´ ì™„ì „íˆ ë‹¤ë¥¸ ë°ì´í„°ì„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
                "\n",
                "> **Lesson**: \"ìˆ«ì(ìš”ì•½ í†µê³„ëŸ‰)ë§Œ ë¯¿ì§€ ë§ê³ , ë°˜ë“œì‹œ ê·¸ë ¤ë³´ì„¸ìš”.\"\n",
                "\n",
                "## 2. Seaborn `regplot`: í•œ ì¤„ë¡œ ëë‚´ëŠ” ì‹œê°í™”\n",
                "ì‚°ì ë„(Scatter)ì™€ íšŒê·€ì„ (Line), ê·¸ë¦¬ê³  95% ì‹ ë¢°êµ¬ê°„(Confidence Interval)ì„ í•œ ë²ˆì— ê·¸ë ¤ì¤ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# ì˜ˆì œ ë°ì´í„°: íŒ ë°ì´í„°ì…‹ (ì‹ì‚¬ ê¸ˆì•¡ vs íŒ)\n",
                "tips = sns.load_dataset(\"tips\")\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "\n",
                "# total_bill(X)ì´ ì»¤ì§€ë©´ tip(Y)ë„ ì»¤ì§€ëŠ”ê°€?\n",
                "sns.regplot(x=\"total_bill\", y=\"tip\", data=tips, line_kws={\"color\": \"red\"})\n",
                "plt.title(\"Total Bill vs Tip (with Regression Line)\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ì”ì°¨ (Residual): ë°ì´í„°ì™€ ëª¨ë¸ì˜ ê±°ë¦¬\n",
                "ìœ„ ê·¸ë˜í”„ì—ì„œ ë¹¨ê°„ ì„ (ì˜ˆì¸¡)ê³¼ íŒŒë€ ì (ì‹¤ì œ) ì‚¬ì´ì˜ ê±°ë¦¬ê°€ ë°”ë¡œ **ì”ì°¨(Error)**ì…ë‹ˆë‹¤.\n",
                "- ì ë“¤ì´ ì„ ì— ë”± ë¶™ì–´ìˆë‹¤ $\\rightarrow$ ëª¨ë¸ ì„±ëŠ¥ì´ ì¢‹ë‹¤ ($R^2$ ë†’ìŒ)\n",
                "- ì ë“¤ì´ ì¤‘êµ¬ë‚œë°©ì´ë‹¤ $\\rightarrow$ ì˜ˆì¸¡ì´ ì–´ë µë‹¤\n",
                "\n",
                "## 3. Correlation Analysis Deep Dive (ìƒê´€ë¶„ì„ ì‹¬í™”)\n",
                "\n",
                "### A. ê³µë¶„ì‚°(Covariance)ì˜ í•œê³„\n",
                "\"í‚¤($X$)ì™€ ëª¸ë¬´ê²Œ($Y$)ì˜ ê³µë¶„ì‚°ì´ 500ì´ë‹¤\"ë¼ëŠ” ë§ì€ ì•„ë¬´ ì˜ë¯¸ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
                "- í‚¤ ë‹¨ìœ„ë¥¼ `cm`ì—ì„œ `m`ë¡œ ë°”ê¾¸ë©´ ê³µë¶„ì‚°ì€ 5ë¡œ ì¤„ì–´ë“­ë‹ˆë‹¤.\n",
                "- **ë‹¨ìœ„(Scale)**ì— ë”°ë¼ ê°’ì´ ë„ë›°ê¸°í•˜ë¯€ë¡œ ì ˆëŒ€ì ì¸ ë¹„êµê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
                "- ê·¸ë˜ì„œ ë‹¨ìœ„ë¥¼ ì—†ì•¤(ì •ê·œí™”í•œ) **ìƒê´€ê³„ìˆ˜($r$)**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
                "\n",
                "### B. ìƒê´€ê³„ìˆ˜($r$) í•´ì„ ê°€ì´ë“œ\n",
                "- **ê°’ì˜ ë²”ìœ„**: $-1 \\sim 1$\n",
                "- **ê°•ë„(Strength)**:\n",
                "    - $|r| > 0.7$: ê°•í•œ ìƒê´€ê´€ê³„\n",
                "    - $|r| < 0.3$: ì•½í•œ ìƒê´€ê´€ê³„ (ê±°ì˜ ê´€ê³„ ì—†ìŒ)\n",
                "- **ë°©í–¥(Direction)**:\n",
                "    - ì–‘ìˆ˜(+): ë¹„ë¡€ (ê³µë¶€ ì‹œê°„ $\\uparrow$ $\\rightarrow$ ì„±ì  $\\uparrow$)\n",
                "    - ìŒìˆ˜(-): ë°˜ë¹„ë¡€ (ê²°ì„ íšŸìˆ˜ $\\uparrow$ $\\rightarrow$ ì„±ì  $\\downarrow$)\n",
                "- **âš ï¸ í•¨ì • (Causation)**: \"ì•„ì´ìŠ¤í¬ë¦¼ íŒë§¤ëŸ‰ê³¼ ìµì‚¬ ì‚¬ê³ ìœ¨ì€ ìƒê´€ê³„ìˆ˜ê°€ ë†’ë‹¤.\" $\\rightarrow$ ì•„ì´ìŠ¤í¬ë¦¼ì´ ìµì‚¬ì˜ ì›ì¸ì¸ê°€? ì•„ë‹˜. **'ì—¬ë¦„(ê¸°ì˜¨)'**ì´ë¼ëŠ” ì œ3ì˜ ë³€ìˆ˜ ë•Œë¬¸.\n",
                "\n",
                "### C. Heatmap ì œëŒ€ë¡œ ì½ê¸°\n",
                "- **ëŒ€ì¹­ì„±**: ëŒ€ê°ì„ (/)ì„ ê¸°ì¤€ìœ¼ë¡œ ëŒ€ì¹­(Decalcomanie)ì…ë‹ˆë‹¤.\n",
                "- **ëŒ€ê°ì„ =1**: ìê¸° ìì‹ ê³¼ì˜ ìƒê´€ê³„ìˆ˜ëŠ” ë¬´ì¡°ê±´ 1ì…ë‹ˆë‹¤.\n",
                "- **ë‹¤ì¤‘ê³µì„ ì„± ê²½ê³ **: ì…ë ¥ ë³€ìˆ˜($X$)ë¼ë¦¬ ë„ˆë¬´ ë¶‰ì€ìƒ‰(ë†’ì€ ìƒê´€ê´€ê³„)ì´ë©´ ì¢‹ì§€ ì•ŠìŠµë‹ˆë‹¤. (ëª¨ë¸ì´ í—·ê°ˆë ¤ í•¨)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(8, 6))\n",
                "# íŒ ë°ì´í„°ì…‹ì˜ ìˆ«ìí˜• ë³€ìˆ˜ë“¤ë§Œ ìƒê´€ê´€ê³„ ë¶„ì„\n",
                "corr_matrix = tips.corr(numeric_only=True)\n",
                "\n",
                "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
                "plt.title(\"Correlation Heatmap: Tips Dataset\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 4. ğŸ§ª Experiment: ì´ìƒì¹˜(Outlier)ì˜ ì˜í–¥ë ¥\n",
                "\n",
                "**\"ì´ìƒì¹˜ í•˜ë‚˜ê°€ ì „ì²´ ëª¨ë¸ì„ ë§ê°€ëœ¨ë¦´ ìˆ˜ ìˆë‹¤\"**ëŠ” ê²ƒì„ ëˆˆìœ¼ë¡œ í™•ì¸í•´ ë´…ì‹œë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì •ìƒ ë°ì´í„° (ìš°ìƒí–¥ íŒ¨í„´)\n",
                "X_normal = np.array([1, 2, 3, 4, 5])\n",
                "y_normal = np.array([1, 2, 3, 4, 5])\n",
                "\n",
                "# ì´ìƒì¹˜ ì¶”ê°€ (X=10ì¸ë° y=-100ì¸ ë§ë„ ì•ˆ ë˜ëŠ” ë°ì´í„°)\n",
                "X_outlier = np.append(X_normal, 10)\n",
                "y_outlier = np.append(y_normal, -100)\n",
                "\n",
                "# ì‹œê°í™”\n",
                "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "# ì •ìƒ ë°ì´í„°\n",
                "sns.regplot(x=X_normal, y=y_normal, ax=ax[0], color='blue')\n",
                "ax[0].set_title(\"Normal Data (Perfect Fit)\")\n",
                "\n",
                "# ì´ìƒì¹˜ í¬í•¨ ë°ì´í„°\n",
                "sns.regplot(x=X_outlier, y=y_outlier, ax=ax[1], color='red')\n",
                "ax[1].set_title(\"With One Outlier (Model Broken)\")\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> **Discussion**: ë‹¨ í•˜ë‚˜ì˜ ì´ìƒì¹˜ê°€ íšŒê·€ì„ (ë¹¨ê°„ ì„ )ì„ ì™„ì „íˆ ì—‰ëš±í•œ ë°©í–¥ìœ¼ë¡œ ëŒê³  ë‚´ë ¤ê°‘ë‹ˆë‹¤. ì´ê²ƒì´ **ì „ì²˜ë¦¬(ì´ìƒì¹˜ ì œê±°)**ê°€ ì¤‘ìš”í•œ ì´ìœ ì…ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# Part 5. ğŸ›  Library Mapping: ì‹¤ì „ ìµœì í™”\n",
                "\n",
                "ìš°ë¦¬ëŠ” ë°˜ë³µë¬¸ìœ¼ë¡œ ê²½ì‚¬í•˜ê°•ë²•ì„ ì§ì ‘ ì§°ì§€ë§Œ(`Part 2`), ì‹¤ë¬´ì—ì„œëŠ” `SGDRegressor`ë¥¼ ì”ë‹ˆë‹¤.\n",
                "ë°˜ë©´ `LinearRegression`ì€ ê²½ì‚¬í•˜ê°•ë²•ì´ ì•„ë‹ˆë¼ í–‰ë ¬ ì—°ì‚°(OLS)ì„ ì‚¬ìš©í•´ ì •ë‹µì„ í•œ ë°©ì— ì°¾ìŠµë‹ˆë‹¤.\n",
                "\n",
                "### 1. SGDRegressor (ê²½ì‚¬í•˜ê°•ë²•)\n",
                "- ë°ì´í„° í•˜ë‚˜ì”© ë³´ë©´ì„œ ì¡°ê¸ˆì”© w, bë¥¼ ìˆ˜ì • (Deep Learning Style)\n",
                "- ë°ì´í„°ê°€ ì—„ì²­ ë§ì„ ë•Œ ë¹ ë¦„\n",
                "\n",
                "### 2. LinearRegression (OLS)\n",
                "- ìˆ˜ì‹ìœ¼ë¡œ í•œ ë°©ì— í‘¼ë‹¤ (Exact Solution)\n",
                "- ë°ì´í„°ê°€ ì ë‹¹í•  ë•Œ ê°€ì¥ ì •í™•í•¨"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import SGDRegressor\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# SGDëŠ” ë°ì´í„° ìŠ¤ì¼€ì¼ì— ë¯¼ê°í•˜ë¯€ë¡œ ì •ê·œí™” í•„ìˆ˜!\n",
                "X_scaled = StandardScaler().fit_transform(X)\n",
                "y_flatten = y.flatten()\n",
                "\n",
                "sgd = SGDRegressor(max_iter=1000, tol=1e-3, learning_rate='constant', eta0=0.01)\n",
                "sgd.fit(X_scaled, y_flatten)\n",
                "\n",
                "print(f\"SGD Coef (w): {sgd.coef_[0]:.4f}\")\n",
                "print(f\"SGD Intercept (b): {sgd.intercept_[0]:.4f}\")\n",
                "# LinearRegressionê³¼ ê±°ì˜ ë¹„ìŠ·í•œ ê²°ê³¼ê°€ ë‚˜ì˜¤ì§€ë§Œ, ê³¼ì •ì€ ë‹¤ë¦…ë‹ˆë‹¤."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}